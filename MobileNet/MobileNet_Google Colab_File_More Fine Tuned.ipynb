{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UHZmFRCdCe-l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d343b081-8ed8-4c85-81c9-f18c416da3a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Files extracted to: /content/extracted_files\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define the path to the ZIP file in your Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/zip-folder.zip'  # Replace with your actual file path\n",
        "extract_to_path = '/content/extracted_files'  # Directory where the ZIP file will be extracted\n",
        "\n",
        "# Step 3: Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_to_path, exist_ok=True)\n",
        "\n",
        "# Step 4: Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "\n",
        "print(f\"Files extracted to: {extract_to_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "780pb8kUGhMl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set paths to your dataset folders\n",
        "train_dir = '/content/extracted_files/train'\n",
        "val_dir = '/content/extracted_files/val'\n",
        "test_dir = '/content/extracted_files/test'"
      ],
      "metadata": {
        "id": "DFBpWwG8Gqui"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model = load_model('/content/drive/MyDrive/mobilenet_finetuned.keras')"
      ],
      "metadata": {
        "id": "jAizqCgcG2Ri",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7795572f-d7ff-4060-ea34-0f8a5864f289"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 87 variables whereas the saved optimizer has 172 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "image_size = (224, 224)  # MobileNet requires 224x224 input size\n",
        "epochs = 20\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "m3qymYbrUi8X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation for Training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)"
      ],
      "metadata": {
        "id": "2nhxfGasU1s7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eMSKiAeBU29i",
        "outputId": "fd513b02-6f93-4b37-f1e4-6fdf417014c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6953 images belonging to 100 classes.\n",
            "Found 1966 images belonging to 100 classes.\n",
            "Found 1034 images belonging to 100 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_accuracy = model.evaluate(train_generator)\n",
        "print(f\"Train Loss: {train_loss:.4f}\\tTrain Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss:.4f}\\tTest Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eZI-LdZhU39q",
        "outputId": "881d63ef-80be-4f8b-af18-ca3d34ee3c59"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 426ms/step - accuracy: 0.9891 - loss: 0.0341\n",
            "Train Loss: 0.0335\tTrain Accuracy: 98.94%\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 177ms/step - accuracy: 0.9983 - loss: 0.0104\n",
            "Test Loss: 0.0071\tTest Accuracy: 99.90%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=learning_rate / 100),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history_final_tune = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5,\n",
        "    validation_data=val_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ltgVLBOhVFFT",
        "outputId": "271b48a4-737c-419d-b017-db6254203687"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 544ms/step - accuracy: 0.9932 - loss: 0.0216 - val_accuracy: 1.0000 - val_loss: 4.9190e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 449ms/step - accuracy: 0.9955 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 3.8513e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 454ms/step - accuracy: 0.9941 - loss: 0.0153 - val_accuracy: 1.0000 - val_loss: 2.1017e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 445ms/step - accuracy: 0.9961 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 1.8116e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 448ms/step - accuracy: 0.9954 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 1.5358e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_accuracy = model.evaluate(train_generator)\n",
        "print(f\"Train Loss: {train_loss:.4f}\\tTrain Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss:.4f}\\tTest Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BamtnLU9VzRZ",
        "outputId": "0a81a549-9b7d-4eca-c907-ba2accd808d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 413ms/step - accuracy: 0.9993 - loss: 0.0036\n",
            "Train Loss: 0.0038\tTrain Accuracy: 99.90%\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 1.2982e-04\n",
            "Test Loss: 0.0002\tTest Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model in the `.keras` format\n",
        "model.save('final_MobileNet_model.keras')\n",
        "\n",
        "# Alternatively, save in the `.h5` format if you prefer\n",
        "model.save('final_MobileNet_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4915H1OWYvKZ",
        "outputId": "68259348-cc50-493f-d218-c2a8bad91d09"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cRfg1PG3ZvIv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}